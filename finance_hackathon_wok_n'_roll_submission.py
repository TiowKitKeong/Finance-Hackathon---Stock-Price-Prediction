# -*- coding: utf-8 -*-
"""Finance_Hackathon-Wok N' Roll_submission.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qxpVBlKwjZtxM4nl5U9cWCIzqYar7rVH
"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import r2_score
from datetime import datetime
from dateutil.relativedelta import relativedelta
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
import xgboost as xgb
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import recall_score, confusion_matrix, precision_score, f1_score, accuracy_score, classification_report
# importing necessary libraries
from sklearn import datasets
from sklearn.metrics import confusion_matrix
import seaborn as sns

import pandas_datareader.data as web

def PricePrediction(each):
    stock_name = each
    df = pd.read_excel(xls, stock_name )
    df = calculateEMA(df,stock_name)
    df = plotRSI(df,stock_name)
    df = calculateVO(df,stock_name)
    df = skipnanrows(df)
    rf = a1_timeframe(df)
    a2_timeframe(df, rf)
    return df

def plotHeatMap(df):
    #Plot correlation matrix
    k = 4 #number of variables for heatmap
    data = df.drop(['Open','Date','High','Low','Volume'], axis=1)
    corrmat2=data.corr()
    cols = corrmat2.nlargest(k, 'Close')['Close'].index
    cm = np.corrcoef(data[cols].values.T)
    sns.set(font_scale=1.2)
    hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)
    plt.show()

# finding EMA
# com value=0.1 (0 approx)
def calculateEMA(df,stock_name):

    ema = df['Close'].ewm(com=13, adjust=False).mean()
    df['EMA'] = ema

    # Comparison plot b/w stock values & EMA
    plt.figure(figsize=(15,15))
    title = "Close Price & EMA Values for "
    title = title + stock_name
    plt.title(title)
    plt.plot(df['Close'], label="Close Price", color="blue")
    plt.plot(df['EMA'], label="EMA Values", color="#ff0000")
    plt.xlabel("Days")
    plt.ylabel("Price")
    plt.legend()
    plt.show()
    return df

def plotRSI(df,stock_name):
    EMA_values = df['EMA']
    delta = df['Close'].diff()
    up = delta.clip(lower=0)
    down = -1*delta.clip(upper=0)
    ema_up = up.ewm(com=13, adjust=False).mean()
    ema_down = down.ewm(com=13, adjust=False).mean()
    rs = ema_up/ema_down
    df['RSI'] = 100 - (100/(1 + rs))
    RSI_values = df['RSI']

    # Skip first 14 days to have real values
    ticker = df.iloc[14:]
    RSI_data = ticker['RSI']

    #print(ticker)
    plt.figure(figsize=(15,15))
    title = "RSI Values for "
    title = title + stock_name
    plt.title(title)
    plt.plot(RSI_data, label="RSA Values", color="#0aa6ff")
    plt.axhline(30, color='r', linestyle='--')
    plt.axhline(70, color='r', linestyle='--')
    plt.xlabel("Days")
    plt.ylabel("RSI Value")
    plt.show()
    return df

import pandas_ta as ta

def calculateVO(df,stock_name):
    #Volume Oscillator
    volume = df["Volume"]
    pvo = df.ta.pvo(volume=volume, fast=14, slow=28, signal=9, scalar=100, offset=0)
    df["PVO"] = pvo["PVO_14_28_9"]
    print(df["PVO"])
    ticker = df.iloc[14:]
    plt.figure(figsize=(15,15))
    title = "PVO Values for "
    title = title + stock_name
    plt.title(title)
    plt.plot(ticker["PVO"], label="Percentage Volume Oscillator", color="#E9184C")
    plt.xlabel("Days")
    plt.ylabel("Values")
    plt.axhline(0, color='b', linestyle='--')
    plt.legend()
    plt.show()
    return df

!pip install pandas_ta

def skipnanrows(df):
    df = df.iloc[27:]
    return df

def a1_timeframe(df):
    df['Date'] = pd.to_datetime(df['Date'])
    end_date = '2021-12-31'
    mask = df['Date'] <= end_date
    a1 = df.loc[mask]
    rf = targetcolumn(a1)
    return rf

def a2_timeframe(df, rf):
    a2 = df
    a2['Date'] = pd.to_datetime(a2['Date'])
    start_date1 = '2021-12-31'
    reversemask = a2['Date'] > start_date1
    a2 = a2.loc[reversemask]
    a2 = a2.iloc[0:90]
    targetcolumn2(a2, rf)

def targetcolumn(a1):
    y = a1['Close']
    X_data = a1.drop(['Open','Date','High','Low','Volume','Close'], axis=1)
    rf = RF(X_data, y)
    return rf

### Grid Search to tune hyperparameter for random forest
def RF(X_data, y):

    X_train_AHEALTH, X_test_AHEALTH, y_train_AHEALTH, y_test_AHEALTH = train_test_split(X_data, y, test_size=0.2, random_state = 42)

    param_grid = {
        'n_estimators' : [50,60,65,70,75,80,85,90,100],
        'max_depth' : [5,6,7,8,9,10,11,12]
    }

    ### Grid Search
    RF=GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=2,n_jobs=3)
    RF.fit(X_train_AHEALTH, y_train_AHEALTH)

    best_params=RF.best_params_

    max_depth=best_params["max_depth"]
    n_estimators=best_params["n_estimators"]

    rf=RandomForestRegressor(random_state=42,n_estimators=n_estimators,max_depth=max_depth)
    rf.fit(X_train_AHEALTH, y_train_AHEALTH)

    # Use the forest's predict method on the test data
    predictions = rf.predict(X_test_AHEALTH)

    # Calculate the absolute errors
    errors = abs(predictions - y_test_AHEALTH)

    # Print out the mean absolute error (mae)
    print('Mean Absolute Error Test:', round(np.mean(errors), 6))
    print("")

    # Calculate mean absolute percentage error (MAPE)
    mape = 100 * (errors / y_test_AHEALTH)

    # Calculate and display accuracy
    accuracy = 100 - np.mean(mape)
    print('Accuracy test:', round(accuracy, 6), '%.')
    print("")

    r_sq = r2_score(y_test_AHEALTH, predictions)
    print('coefficient of determination:', np.round(r_sq,6))

    return rf

def targetcolumn2(a2, rf):
    a2_clone = a2.drop(['Open','Date','High','Low','Volume','Close'], axis=1)
    close_a2 = a2['Close']
    RF_predict(a2_clone, a2, rf, close_a2)

def RF_predict(a2_clone, a2, rf, close_a2):
    predictions1 = rf.predict(a2_clone)
    #comparison plot actual vs predicted close price graph
    x = a2["Date"]
    a2['Predicted Close'] = predictions1
    a2.rename(columns = {'Close':'Actual Close'}, inplace = True)
    print(a2[['Date','Actual Close','Predicted Close']])
    plt.figure(figsize=(15,15))
    title = "Actual Close Price vs Predicted Close Price for "
    title = title + stock_name
    plt.title(title)
    plt.plot(a2['Actual Close'], label="Actual Close Price", color="blue")
    plt.plot(a2['Predicted Close'], label="Predicted Close Price", color="#ff0000")
    plt.xlabel("Days")
    plt.ylabel("Price")
    plt.legend()
    plt.show()

    errors = abs(predictions1 - close_a2)
    # Print out the mean absolute error (mae)
    print('Mean Absolute Error Test:', round(np.mean(errors), 6))
    print("")
    # Calculate mean absolute percentage error (MAPE)
    mape = 100 * (errors / close_a2)
    # Calculate and display accuracy
    accuracy = 100 - np.mean(mape)
    print('Accuracy test:', round(accuracy, 6), '%.')
    print("")
    r_sq = r2_score(close_a2, predictions1)
    print('coefficient of determination:', np.round(r_sq,6))
    errors = abs(predictions1 - close_a2)

    # Print out the mean absolute error (mae)
    print('Mean Absolute Error Test:', round(np.mean(errors), 6))
    print("")

    # Calculate mean absolute percentage error (MAPE)
    mape = 100 * (errors / close_a2)

    # Calculate and display accuracy
    accuracy = 100 - np.mean(mape)
    print('Accuracy test:', round(accuracy, 6), '%.')
    print("")

    r_sq = r2_score(close_a2, predictions1)
    print('coefficient of determination:', np.round(r_sq,6))

def DirectionalPrediction(df):
    print("Directional Classifier")
    df["Direction"] = "x"
    x = df.Open
    y = df.Close
    z = df.Direction
    start = 27
    for i in range(start,(len(df.Direction)+start)):
        if x[i] == y[i]:
            z[i] = "sideways"
        elif x[i] > y[i]:
            z[i] = "bullish"
        else:
            z[i] = "bearish"

    #print(AHEALTH["Direction"])

    # Encode the three classes: ,"bullish","sideways",bearish" into 0,1,2 respectively.
    df['Direction'] = df['Direction'].map({'bullish' :0, 'sideways' :1, 'bearish' :2}).astype(int)

    #Plot correlation matrix
    k = 4 #number of variables for heatmap
    data = df.drop(['Open','Date','High','Low','Volume','Close'], axis=1)
    corrmat2=data.corr()
    cols = corrmat2.nlargest(k, "Direction")["Direction"].index
    cm = np.corrcoef(data[cols].values.T)
    sns.set(font_scale=1.2)
    hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)
    plt.show()

    end_date = '2021-12-31'
    mask = df['Date'] <= end_date
    a3 = df.loc[mask]
    display(a3)

    x = a3.drop(['Open','Date','High','Low','Volume','Close',"Direction"], axis=1)
    x = x.iloc[:-1]
    y = a3["Direction"]
    y = y.iloc[1:]

    # dividing X, y into train and test data
    X_train, X_test, y_train, y_test = train_test_split(x, y,random_state = 42)


    #Naive Bayes Model
    from sklearn.model_selection import GridSearchCV
    from sklearn.naive_bayes import GaussianNB
    print()
    print("Naive Bayes Model")
    print()
    param_grid_nb = {'var_smoothing':np.logspace(0,-19,num=100)}
    nbModel_grid = GridSearchCV(estimator=GaussianNB(), param_grid=param_grid_nb, verbose=1, cv=10, n_jobs=-1)
    gnb=nbModel_grid.fit(X_train, y_train)
    # training a Naive Bayes classifier
    gnb_predictions = gnb.predict(X_test)

    # accuracy on X_test
    accuracy = gnb.score(X_test, y_test)

    # creating a confusion matrix
    cm = confusion_matrix(y_test, gnb_predictions)
    conf_matrix = pd.DataFrame(data = cm,
    columns = ['Predicted:0', 'Predicted:1','Predicted:2'],
    index =['Actual:0', 'Actual:1',"Actual:2"])
    plt.figure(figsize = (8, 5))
    sns.heatmap(conf_matrix, annot = True, fmt = 'd', cmap = "Greens")
    plt.show()
    print()
    print('The details for confusion matrix is =')
    print (classification_report(y_test, gnb_predictions))
    print()
    print(accuracy)
    print(cm)
    print()
    print()

    #XGBoost model
    print()
    print("XGBoost Model")
    print()
    X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 42)
    xgb_model = xgb.XGBClassifier(objective="multi:softprob", random_state=42)
    xgb_model.fit(X_train, y_train)

    y_pred = xgb_model.predict(X_test)
    accuracy = xgb_model.score(X_test,y_test)
    cm = confusion_matrix(y_test, y_pred)

    conf_matrix = pd.DataFrame(data = cm,
    columns = ['Predicted:0', 'Predicted:1','Predicted:2'],
    index =['Actual:0', 'Actual:1',"Actual:2"])
    plt.figure(figsize = (8, 5))
    sns.heatmap(conf_matrix, annot = True, fmt = 'd', cmap = "Greens")
    plt.show()

    print('The details for confusion matrix is =')
    print (classification_report(y_test, y_pred))
    print()
    print(accuracy)
    print(cm)
    print()
    print()

!pip install xgboost

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

xls = pd.ExcelFile(r"/content/Capital Dynamics - Dataset.xlsx")

# stocks = ["AHEALTH","APM","BIOHLDG","BSTEAD","CAPITALA","EUPE","HPMT","ICAP" ,"KGB" ,"KRONO" ,"LUXCHEM"
#           ,"MKH" ,"OCK", "OCNCASH", "PADINI", "PARKSON", "SALUTE", "SAM", "SURIA","TONGHER" ,"UTDPLT" ,"WELLCAL"]
stocks = ["AHEALTH","KRONO","WELLCAL"]
stock_name=""
for each in stocks:
    stock_name = each
    df = PricePrediction(each)
    plotHeatMap(df)
    DirectionalPrediction(df)
    #df = AHEALTH